Task4 å»ºæ¨¡ä¸Žè°ƒå‚
æ­¤éƒ¨åˆ†ä¸ºé›¶åŸºç¡€å…¥é—¨é‡‘èžé£ŽæŽ§çš„ Task4 å»ºæ¨¡è°ƒå‚éƒ¨åˆ†ï¼Œå¸¦ä½ æ¥äº†è§£å„ç§æ¨¡åž‹ä»¥åŠæ¨¡åž‹çš„è¯„ä»·å’Œè°ƒå‚ç­–ç•¥ï¼Œæ¬¢è¿Žå¤§å®¶åŽç»­å¤šå¤šäº¤æµã€‚

èµ›é¢˜ï¼šé›¶åŸºç¡€å…¥é—¨æ•°æ®æŒ–æŽ˜ - é›¶åŸºç¡€å…¥é—¨é‡‘èžé£ŽæŽ§ä¹‹è´·æ¬¾è¿çº¦é¢„æµ‹

4.1 å­¦ä¹ ç›®æ ‡
å­¦ä¹ åœ¨é‡‘èžåˆ†æŽ§é¢†åŸŸå¸¸ç”¨çš„æœºå™¨å­¦ä¹ æ¨¡åž‹
å­¦ä¹ æœºå™¨å­¦ä¹ æ¨¡åž‹çš„å»ºæ¨¡è¿‡ç¨‹ä¸Žè°ƒå‚æµç¨‹
å®Œæˆç›¸åº”å­¦ä¹ æ‰“å¡ä»»åŠ¡
4.2 å†…å®¹ä»‹ç»
é€»è¾‘å›žå½’æ¨¡åž‹ï¼š

ç†è§£é€»è¾‘å›žå½’æ¨¡åž‹ï¼›
é€»è¾‘å›žå½’æ¨¡åž‹çš„åº”ç”¨ï¼›
é€»è¾‘å›žå½’çš„ä¼˜ç¼ºç‚¹ï¼›
æ ‘æ¨¡åž‹ï¼š

ç†è§£æ ‘æ¨¡åž‹ï¼›
æ ‘æ¨¡åž‹çš„åº”ç”¨ï¼›
æ ‘æ¨¡åž‹çš„ä¼˜ç¼ºç‚¹ï¼›
é›†æˆæ¨¡åž‹

åŸºäºŽbaggingæ€æƒ³çš„é›†æˆæ¨¡åž‹
éšæœºæ£®æž—æ¨¡åž‹
åŸºäºŽboostingæ€æƒ³çš„é›†æˆæ¨¡åž‹
XGBoostæ¨¡åž‹
LightGBMæ¨¡åž‹
CatBoostæ¨¡åž‹
æ¨¡åž‹å¯¹æ¯”ä¸Žæ€§èƒ½è¯„ä¼°ï¼š

å›žå½’æ¨¡åž‹/æ ‘æ¨¡åž‹/é›†æˆæ¨¡åž‹ï¼›
æ¨¡åž‹è¯„ä¼°æ–¹æ³•ï¼›
æ¨¡åž‹è¯„ä»·ç»“æžœï¼›
æ¨¡åž‹è°ƒå‚ï¼š

è´ªå¿ƒè°ƒå‚æ–¹æ³•ï¼›

ç½‘æ ¼è°ƒå‚æ–¹æ³•ï¼›

è´å¶æ–¯è°ƒå‚æ–¹æ³•ï¼›

4.3 æ¨¡åž‹ç›¸å…³åŽŸç†ä»‹ç»
ç”±äºŽç›¸å…³ç®—æ³•åŽŸç†ç¯‡å¹…è¾ƒé•¿ï¼Œæœ¬æ–‡æŽ¨èäº†ä¸€äº›åšå®¢ä¸Žæ•™æä¾›åˆå­¦è€…ä»¬è¿›è¡Œå­¦ä¹ ã€‚

4.3.1 é€»è¾‘å›žå½’æ¨¡åž‹
https://blog.csdn.net/han_xiaoyang/article/details/49123419

4.3.2 å†³ç­–æ ‘æ¨¡åž‹
https://blog.csdn.net/c406495762/article/details/76262487

4.3.3 GBDTæ¨¡åž‹
https://zhuanlan.zhihu.com/p/45145899

4.3.4 XGBoostæ¨¡åž‹
https://blog.csdn.net/wuzhongqiang/article/details/104854890

4.3.5 LightGBMæ¨¡åž‹
https://blog.csdn.net/wuzhongqiang/article/details/105350579

4.3.6 Catboostæ¨¡åž‹
https://mp.weixin.qq.com/s/xloTLr5NJBgBspMQtxPoFA

4.3.7 æ—¶é—´åºåˆ—æ¨¡åž‹(é€‰å­¦)
RNNï¼šhttps://zhuanlan.zhihu.com/p/45289691

LSTMï¼šhttps://zhuanlan.zhihu.com/p/83496936

4.3.8 æŽ¨èæ•™æï¼š
ã€Šæœºå™¨å­¦ä¹ ã€‹ https://book.douban.com/subject/26708119/

ã€Šç»Ÿè®¡å­¦ä¹ æ–¹æ³•ã€‹ https://book.douban.com/subject/10590856/

ã€Šé¢å‘æœºå™¨å­¦ä¹ çš„ç‰¹å¾å·¥ç¨‹ã€‹ https://book.douban.com/subject/26826639/

ã€Šä¿¡ç”¨è¯„åˆ†æ¨¡åž‹æŠ€æœ¯ä¸Žåº”ç”¨ã€‹https://book.douban.com/subject/1488075/

ã€Šæ•°æ®åŒ–é£ŽæŽ§ã€‹https://book.douban.com/subject/30282558/

4.4 æ¨¡åž‹å¯¹æ¯”ä¸Žæ€§èƒ½è¯„ä¼°
4.4.1 é€»è¾‘å›žå½’
ä¼˜ç‚¹

è®­ç»ƒé€Ÿåº¦è¾ƒå¿«ï¼Œåˆ†ç±»çš„æ—¶å€™ï¼Œè®¡ç®—é‡ä»…ä»…åªå’Œç‰¹å¾çš„æ•°ç›®ç›¸å…³ï¼›
ç®€å•æ˜“ç†è§£ï¼Œæ¨¡åž‹çš„å¯è§£é‡Šæ€§éžå¸¸å¥½ï¼Œä»Žç‰¹å¾çš„æƒé‡å¯ä»¥çœ‹åˆ°ä¸åŒçš„ç‰¹å¾å¯¹æœ€åŽç»“æžœçš„å½±å“ï¼›
é€‚åˆäºŒåˆ†ç±»é—®é¢˜ï¼Œä¸éœ€è¦ç¼©æ”¾è¾“å…¥ç‰¹å¾ï¼›
å†…å­˜èµ„æºå ç”¨å°ï¼Œåªéœ€è¦å­˜å‚¨å„ä¸ªç»´åº¦çš„ç‰¹å¾å€¼ï¼›
ç¼ºç‚¹

é€»è¾‘å›žå½’éœ€è¦é¢„å…ˆå¤„ç†ç¼ºå¤±å€¼å’Œå¼‚å¸¸å€¼ã€å¯å‚è€ƒtask3ç‰¹å¾å·¥ç¨‹ã€‘ï¼›

ä¸èƒ½ç”¨Logisticå›žå½’åŽ»è§£å†³éžçº¿æ€§é—®é¢˜ï¼Œå› ä¸ºLogisticçš„å†³ç­–é¢æ˜¯çº¿æ€§çš„ï¼›

å¯¹å¤šé‡å…±çº¿æ€§æ•°æ®è¾ƒä¸ºæ•æ„Ÿï¼Œä¸”å¾ˆéš¾å¤„ç†æ•°æ®ä¸å¹³è¡¡çš„é—®é¢˜ï¼›

å‡†ç¡®çŽ‡å¹¶ä¸æ˜¯å¾ˆé«˜ï¼Œå› ä¸ºå½¢å¼éžå¸¸ç®€å•ï¼Œå¾ˆéš¾åŽ»æ‹Ÿåˆæ•°æ®çš„çœŸå®žåˆ†å¸ƒï¼›

4.4.2 å†³ç­–æ ‘æ¨¡åž‹
ä¼˜ç‚¹
ç®€å•ç›´è§‚ï¼Œç”Ÿæˆçš„å†³ç­–æ ‘å¯ä»¥å¯è§†åŒ–å±•ç¤º
æ•°æ®ä¸éœ€è¦é¢„å¤„ç†ï¼Œä¸éœ€è¦å½’ä¸€åŒ–ï¼Œä¸éœ€è¦å¤„ç†ç¼ºå¤±æ•°æ®
æ—¢å¯ä»¥å¤„ç†ç¦»æ•£å€¼ï¼Œä¹Ÿå¯ä»¥å¤„ç†è¿žç»­å€¼
ç¼ºç‚¹
å†³ç­–æ ‘ç®—æ³•éžå¸¸å®¹æ˜“è¿‡æ‹Ÿåˆï¼Œå¯¼è‡´æ³›åŒ–èƒ½åŠ›ä¸å¼ºï¼ˆå¯è¿›è¡Œé€‚å½“çš„å‰ªæžï¼‰
é‡‡ç”¨çš„æ˜¯è´ªå¿ƒç®—æ³•ï¼Œå®¹æ˜“å¾—åˆ°å±€éƒ¨æœ€ä¼˜è§£
4.4.3 é›†æˆæ¨¡åž‹é›†æˆæ–¹æ³•ï¼ˆensemble methodï¼‰
é€šè¿‡ç»„åˆå¤šä¸ªå­¦ä¹ å™¨æ¥å®Œæˆå­¦ä¹ ä»»åŠ¡ï¼Œé€šè¿‡é›†æˆæ–¹æ³•ï¼Œå¯ä»¥å°†å¤šä¸ªå¼±å­¦ä¹ å™¨ç»„åˆæˆä¸€ä¸ªå¼ºåˆ†ç±»å™¨ï¼Œå› æ­¤é›†æˆå­¦ä¹ çš„æ³›åŒ–èƒ½åŠ›ä¸€èˆ¬æ¯”å•ä¸€åˆ†ç±»å™¨è¦å¥½ã€‚

é›†æˆæ–¹æ³•ä¸»è¦åŒ…æ‹¬Baggingå’ŒBoostingï¼ŒBaggingå’ŒBoostingéƒ½æ˜¯å°†å·²æœ‰çš„åˆ†ç±»æˆ–å›žå½’ç®—æ³•é€šè¿‡ä¸€å®šæ–¹å¼ç»„åˆèµ·æ¥ï¼Œå½¢æˆä¸€ä¸ªæ›´åŠ å¼ºå¤§çš„åˆ†ç±»ã€‚ä¸¤ç§æ–¹æ³•éƒ½æ˜¯æŠŠè‹¥å¹²ä¸ªåˆ†ç±»å™¨æ•´åˆä¸ºä¸€ä¸ªåˆ†ç±»å™¨çš„æ–¹æ³•ï¼Œåªæ˜¯æ•´åˆçš„æ–¹å¼ä¸ä¸€æ ·ï¼Œæœ€ç»ˆå¾—åˆ°ä¸ä¸€æ ·çš„æ•ˆæžœã€‚å¸¸è§çš„åŸºäºŽBagginæ€æƒ³çš„é›†æˆæ¨¡åž‹æœ‰ï¼šéšæœºæ£®æž—ã€åŸºäºŽBoostingæ€æƒ³çš„é›†æˆæ¨¡åž‹æœ‰ï¼šAdaboostã€GBDTã€XgBoostã€LightGBMç­‰ã€‚

Bagginå’ŒBoostingçš„åŒºåˆ«æ€»ç»“å¦‚ä¸‹ï¼š

æ ·æœ¬é€‰æ‹©ä¸Šï¼š Baggingæ–¹æ³•çš„è®­ç»ƒé›†æ˜¯ä»ŽåŽŸå§‹é›†ä¸­æœ‰æ”¾å›žçš„é€‰å–ï¼Œæ‰€ä»¥ä»ŽåŽŸå§‹é›†ä¸­é€‰å‡ºçš„å„è½®è®­ç»ƒé›†ä¹‹é—´æ˜¯ç‹¬ç«‹çš„ï¼›è€ŒBoostingæ–¹æ³•éœ€è¦æ¯ä¸€è½®çš„è®­ç»ƒé›†ä¸å˜ï¼Œåªæ˜¯è®­ç»ƒé›†ä¸­æ¯ä¸ªæ ·æœ¬åœ¨åˆ†ç±»å™¨ä¸­çš„æƒé‡å‘ç”Ÿå˜åŒ–ã€‚è€Œæƒå€¼æ˜¯æ ¹æ®ä¸Šä¸€è½®çš„åˆ†ç±»ç»“æžœè¿›è¡Œè°ƒæ•´
æ ·ä¾‹æƒé‡ä¸Šï¼š Baggingæ–¹æ³•ä½¿ç”¨å‡åŒ€å–æ ·ï¼Œæ‰€ä»¥æ¯ä¸ªæ ·æœ¬çš„æƒé‡ç›¸ç­‰ï¼›è€ŒBoostingæ–¹æ³•æ ¹æ®é”™è¯¯çŽ‡ä¸æ–­è°ƒæ•´æ ·æœ¬çš„æƒå€¼ï¼Œé”™è¯¯çŽ‡è¶Šå¤§åˆ™æƒé‡è¶Šå¤§
é¢„æµ‹å‡½æ•°ä¸Šï¼š Baggingæ–¹æ³•ä¸­æ‰€æœ‰é¢„æµ‹å‡½æ•°çš„æƒé‡ç›¸ç­‰ï¼›è€ŒBoostingæ–¹æ³•ä¸­æ¯ä¸ªå¼±åˆ†ç±»å™¨éƒ½æœ‰ç›¸åº”çš„æƒé‡ï¼Œå¯¹äºŽåˆ†ç±»è¯¯å·®å°çš„åˆ†ç±»å™¨ä¼šæœ‰æ›´å¤§çš„æƒé‡
å¹¶è¡Œè®¡ç®—ä¸Šï¼š Baggingæ–¹æ³•ä¸­å„ä¸ªé¢„æµ‹å‡½æ•°å¯ä»¥å¹¶è¡Œç”Ÿæˆï¼›è€ŒBoostingæ–¹æ³•å„ä¸ªé¢„æµ‹å‡½æ•°åªèƒ½é¡ºåºç”Ÿæˆï¼Œå› ä¸ºåŽä¸€ä¸ªæ¨¡åž‹å‚æ•°éœ€è¦å‰ä¸€è½®æ¨¡åž‹çš„ç»“æžœã€‚
4.4.4 æ¨¡åž‹è¯„ä¼°æ–¹æ³•
å¯¹äºŽæ¨¡åž‹æ¥è¯´ï¼Œå…¶åœ¨è®­ç»ƒé›†ä¸Šé¢çš„è¯¯å·®æˆ‘ä»¬ç§°ä¹‹ä¸ºè®­ç»ƒè¯¯å·®æˆ–è€…ç»éªŒè¯¯å·®ï¼Œè€Œåœ¨æµ‹è¯•é›†ä¸Šçš„è¯¯å·®ç§°ä¹‹ä¸ºæµ‹è¯•è¯¯å·®ã€‚

å¯¹äºŽæˆ‘ä»¬æ¥è¯´ï¼Œæˆ‘ä»¬æ›´å…³å¿ƒçš„æ˜¯æ¨¡åž‹å¯¹äºŽæ–°æ ·æœ¬çš„å­¦ä¹ èƒ½åŠ›ï¼Œå³æˆ‘ä»¬å¸Œæœ›é€šè¿‡å¯¹å·²æœ‰æ ·æœ¬çš„å­¦ä¹ ï¼Œå°½å¯èƒ½çš„å°†æ‰€æœ‰æ½œåœ¨æ ·æœ¬çš„æ™®éè§„å¾‹å­¦åˆ°æ‰‹ï¼Œè€Œå¦‚æžœæ¨¡åž‹å¯¹è®­ç»ƒæ ·æœ¬å­¦çš„å¤ªå¥½ï¼Œåˆ™æœ‰å¯èƒ½æŠŠè®­ç»ƒæ ·æœ¬è‡ªèº«æ‰€å…·æœ‰çš„ä¸€äº›ç‰¹ç‚¹å½“åšæ‰€æœ‰æ½œåœ¨æ ·æœ¬çš„æ™®éç‰¹ç‚¹ï¼Œè¿™æ—¶å€™æˆ‘ä»¬å°±ä¼šå‡ºçŽ°è¿‡æ‹Ÿåˆçš„é—®é¢˜ã€‚

å› æ­¤æˆ‘ä»¬é€šå¸¸å°†å·²æœ‰çš„æ•°æ®é›†åˆ’åˆ†ä¸ºè®­ç»ƒé›†å’Œæµ‹è¯•é›†ä¸¤éƒ¨åˆ†ï¼Œå…¶ä¸­è®­ç»ƒé›†ç”¨æ¥è®­ç»ƒæ¨¡åž‹ï¼Œè€Œæµ‹è¯•é›†åˆ™æ˜¯ç”¨æ¥è¯„ä¼°æ¨¡åž‹å¯¹äºŽæ–°æ ·æœ¬çš„åˆ¤åˆ«èƒ½åŠ›ã€‚

å¯¹äºŽæ•°æ®é›†çš„åˆ’åˆ†ï¼Œæˆ‘ä»¬é€šå¸¸è¦ä¿è¯æ»¡è¶³ä»¥ä¸‹ä¸¤ä¸ªæ¡ä»¶ï¼š

è®­ç»ƒé›†å’Œæµ‹è¯•é›†çš„åˆ†å¸ƒè¦ä¸Žæ ·æœ¬çœŸå®žåˆ†å¸ƒä¸€è‡´ï¼Œå³è®­ç»ƒé›†å’Œæµ‹è¯•é›†éƒ½è¦ä¿è¯æ˜¯ä»Žæ ·æœ¬çœŸå®žåˆ†å¸ƒä¸­ç‹¬ç«‹åŒåˆ†å¸ƒé‡‡æ ·è€Œå¾—ï¼›
è®­ç»ƒé›†å’Œæµ‹è¯•é›†è¦äº’æ–¥
å¯¹äºŽæ•°æ®é›†çš„åˆ’åˆ†æœ‰ä¸‰ç§æ–¹æ³•ï¼šç•™å‡ºæ³•ï¼Œäº¤å‰éªŒè¯æ³•å’Œè‡ªåŠ©æ³•ï¼Œä¸‹é¢æŒ¨ä¸ªä»‹ç»ï¼š

â‘ ç•™å‡ºæ³•

ç•™å‡ºæ³•æ˜¯ç›´æŽ¥å°†æ•°æ®é›†Dåˆ’åˆ†ä¸ºä¸¤ä¸ªäº’æ–¥çš„é›†åˆï¼Œå…¶ä¸­ä¸€ä¸ªé›†åˆä½œä¸ºè®­ç»ƒé›†Sï¼Œå¦ä¸€ä¸ªä½œä¸ºæµ‹è¯•é›†Tã€‚éœ€è¦æ³¨æ„çš„æ˜¯åœ¨åˆ’åˆ†çš„æ—¶å€™è¦å°½å¯èƒ½ä¿è¯æ•°æ®åˆ†å¸ƒçš„ä¸€è‡´æ€§ï¼Œå³é¿å…å› æ•°æ®åˆ’åˆ†è¿‡ç¨‹å¼•å…¥é¢å¤–çš„åå·®è€Œå¯¹æœ€ç»ˆç»“æžœäº§ç”Ÿå½±å“ã€‚ä¸ºäº†ä¿è¯æ•°æ®åˆ†å¸ƒçš„ä¸€è‡´æ€§ï¼Œé€šå¸¸æˆ‘ä»¬é‡‡ç”¨åˆ†å±‚é‡‡æ ·çš„æ–¹å¼æ¥å¯¹æ•°æ®è¿›è¡Œé‡‡æ ·ã€‚

Tipsï¼š é€šå¸¸ï¼Œä¼šå°†æ•°æ®é›†Dä¸­å¤§çº¦2/3~4/5çš„æ ·æœ¬ä½œä¸ºè®­ç»ƒé›†ï¼Œå…¶ä½™çš„ä½œä¸ºæµ‹è¯•é›†ã€‚

â‘¡äº¤å‰éªŒè¯æ³•

kæŠ˜äº¤å‰éªŒè¯é€šå¸¸å°†æ•°æ®é›†Dåˆ†ä¸ºkä»½ï¼Œå…¶ä¸­k-1ä»½ä½œä¸ºè®­ç»ƒé›†ï¼Œå‰©ä½™çš„ä¸€ä»½ä½œä¸ºæµ‹è¯•é›†ï¼Œè¿™æ ·å°±å¯ä»¥èŽ·å¾—kç»„è®­ç»ƒ/æµ‹è¯•é›†ï¼Œå¯ä»¥è¿›è¡Œkæ¬¡è®­ç»ƒä¸Žæµ‹è¯•ï¼Œæœ€ç»ˆè¿”å›žçš„æ˜¯kä¸ªæµ‹è¯•ç»“æžœçš„å‡å€¼ã€‚äº¤å‰éªŒè¯ä¸­æ•°æ®é›†çš„åˆ’åˆ†ä¾ç„¶æ˜¯ä¾æ®åˆ†å±‚é‡‡æ ·çš„æ–¹å¼æ¥è¿›è¡Œã€‚

å¯¹äºŽäº¤å‰éªŒè¯æ³•ï¼Œå…¶kå€¼çš„é€‰å–å¾€å¾€å†³å®šäº†è¯„ä¼°ç»“æžœçš„ç¨³å®šæ€§å’Œä¿çœŸæ€§ï¼Œé€šå¸¸kå€¼é€‰å–10ã€‚

å½“k=1çš„æ—¶å€™ï¼Œæˆ‘ä»¬ç§°ä¹‹ä¸ºç•™ä¸€æ³•

â‘¢è‡ªåŠ©æ³•

æˆ‘ä»¬æ¯æ¬¡ä»Žæ•°æ®é›†Dä¸­å–ä¸€ä¸ªæ ·æœ¬ä½œä¸ºè®­ç»ƒé›†ä¸­çš„å…ƒç´ ï¼Œç„¶åŽæŠŠè¯¥æ ·æœ¬æ”¾å›žï¼Œé‡å¤è¯¥è¡Œä¸ºmæ¬¡ï¼Œè¿™æ ·æˆ‘ä»¬å°±å¯ä»¥å¾—åˆ°å¤§å°ä¸ºmçš„è®­ç»ƒé›†ï¼Œåœ¨è¿™é‡Œé¢æœ‰çš„æ ·æœ¬é‡å¤å‡ºçŽ°ï¼Œæœ‰çš„æ ·æœ¬åˆ™æ²¡æœ‰å‡ºçŽ°è¿‡ï¼Œæˆ‘ä»¬æŠŠé‚£äº›æ²¡æœ‰å‡ºçŽ°è¿‡çš„æ ·æœ¬ä½œä¸ºæµ‹è¯•é›†ã€‚

è¿›è¡Œè¿™æ ·é‡‡æ ·çš„åŽŸå› æ˜¯å› ä¸ºåœ¨Dä¸­çº¦æœ‰36.8%çš„æ•°æ®æ²¡æœ‰åœ¨è®­ç»ƒé›†ä¸­å‡ºçŽ°è¿‡ã€‚ç•™å‡ºæ³•ä¸Žäº¤å‰éªŒè¯æ³•éƒ½æ˜¯ä½¿ç”¨åˆ†å±‚é‡‡æ ·çš„æ–¹å¼è¿›è¡Œæ•°æ®é‡‡æ ·ä¸Žåˆ’åˆ†ï¼Œè€Œè‡ªåŠ©æ³•åˆ™æ˜¯ä½¿ç”¨æœ‰æ”¾å›žé‡å¤é‡‡æ ·çš„æ–¹å¼è¿›è¡Œæ•°æ®é‡‡æ ·

æ•°æ®é›†åˆ’åˆ†æ€»ç»“

å¯¹äºŽæ•°æ®é‡å……è¶³çš„æ—¶å€™ï¼Œé€šå¸¸é‡‡ç”¨ç•™å‡ºæ³•æˆ–è€…kæŠ˜äº¤å‰éªŒè¯æ³•æ¥è¿›è¡Œè®­ç»ƒ/æµ‹è¯•é›†çš„åˆ’åˆ†ï¼›
å¯¹äºŽæ•°æ®é›†å°ä¸”éš¾ä»¥æœ‰æ•ˆåˆ’åˆ†è®­ç»ƒ/æµ‹è¯•é›†æ—¶ä½¿ç”¨è‡ªåŠ©æ³•ï¼›
å¯¹äºŽæ•°æ®é›†å°ä¸”å¯æœ‰æ•ˆåˆ’åˆ†çš„æ—¶å€™æœ€å¥½ä½¿ç”¨ç•™ä¸€æ³•æ¥è¿›è¡Œåˆ’åˆ†ï¼Œå› ä¸ºè¿™ç§æ–¹æ³•æœ€ä¸ºå‡†ç¡®
4.4.5 æ¨¡åž‹è¯„ä»·æ ‡å‡†
å¯¹äºŽæœ¬æ¬¡æ¯”èµ›ï¼Œæˆ‘ä»¬é€‰ç”¨aucä½œä¸ºæ¨¡åž‹è¯„ä»·æ ‡å‡†ï¼Œç±»ä¼¼çš„è¯„ä»·æ ‡å‡†è¿˜æœ‰ksã€f1-scoreç­‰ï¼Œå…·ä½“ä»‹ç»ä¸Žå®žçŽ°å¤§å®¶å¯ä»¥å›žé¡¾ä¸‹task1ä¸­çš„å†…å®¹ã€‚

ä¸€èµ·æ¥çœ‹ä¸€ä¸‹aucåˆ°åº•æ˜¯ä»€ä¹ˆï¼Ÿ

åœ¨é€»è¾‘å›žå½’é‡Œé¢ï¼Œå¯¹äºŽæ­£è´Ÿä¾‹çš„ç•Œå®šï¼Œé€šå¸¸ä¼šè®¾ä¸€ä¸ªé˜ˆå€¼ï¼Œå¤§äºŽé˜ˆå€¼çš„ä¸ºæ­£ç±»ï¼Œå°äºŽé˜ˆå€¼ä¸ºè´Ÿç±»ã€‚å¦‚æžœæˆ‘ä»¬å‡å°è¿™ä¸ªé˜€å€¼ï¼Œæ›´å¤šçš„æ ·æœ¬ä¼šè¢«è¯†åˆ«ä¸ºæ­£ç±»ï¼Œæé«˜æ­£ç±»çš„è¯†åˆ«çŽ‡ï¼Œä½†åŒæ—¶ä¹Ÿä¼šä½¿å¾—æ›´å¤šçš„è´Ÿç±»è¢«é”™è¯¯è¯†åˆ«ä¸ºæ­£ç±»ã€‚ä¸ºäº†ç›´è§‚è¡¨ç¤ºè¿™ä¸€çŽ°è±¡ï¼Œå¼•å…¥ROCã€‚

æ ¹æ®åˆ†ç±»ç»“æžœè®¡ç®—å¾—åˆ°ROCç©ºé—´ä¸­ç›¸åº”çš„ç‚¹ï¼Œè¿žæŽ¥è¿™äº›ç‚¹å°±å½¢æˆROC curveï¼Œæ¨ªåæ ‡ä¸ºFalse Positive Rate(FPRï¼šå‡æ­£çŽ‡)ï¼Œçºµåæ ‡ä¸ºTrue Positive Rate(TPRï¼šçœŸæ­£çŽ‡)ã€‚ ä¸€èˆ¬æƒ…å†µä¸‹ï¼Œè¿™ä¸ªæ›²çº¿éƒ½åº”è¯¥å¤„äºŽ(0,0)å’Œ(1,1)è¿žçº¿çš„ä¸Šæ–¹,å¦‚å›¾ï¼š

ROC&AUC.png

ROCæ›²çº¿ä¸­çš„å››ä¸ªç‚¹ï¼š

ç‚¹(0,1)ï¼šå³FPR=0, TPR=1ï¼Œæ„å‘³ç€FNï¼0ä¸”FPï¼0ï¼Œå°†æ‰€æœ‰çš„æ ·æœ¬éƒ½æ­£ç¡®åˆ†ç±»ï¼›
ç‚¹(1,0)ï¼šå³FPR=1ï¼ŒTPR=0ï¼Œæœ€å·®åˆ†ç±»å™¨ï¼Œé¿å¼€äº†æ‰€æœ‰æ­£ç¡®ç­”æ¡ˆï¼›
ç‚¹(0,0)ï¼šå³FPR=TPR=0ï¼ŒFPï¼TPï¼0ï¼Œåˆ†ç±»å™¨æŠŠæ¯ä¸ªå®žä¾‹éƒ½é¢„æµ‹ä¸ºè´Ÿç±»ï¼›
ç‚¹(1,1)ï¼šåˆ†ç±»å™¨æŠŠæ¯ä¸ªå®žä¾‹éƒ½é¢„æµ‹ä¸ºæ­£ç±»
æ€»ä¹‹ï¼šROCæ›²çº¿è¶ŠæŽ¥è¿‘å·¦ä¸Šè§’ï¼Œè¯¥åˆ†ç±»å™¨çš„æ€§èƒ½è¶Šå¥½ï¼Œå…¶æ³›åŒ–æ€§èƒ½å°±è¶Šå¥½ã€‚è€Œä¸”ä¸€èˆ¬æ¥è¯´ï¼Œå¦‚æžœROCæ˜¯å…‰æ»‘çš„ï¼Œé‚£ä¹ˆåŸºæœ¬å¯ä»¥åˆ¤æ–­æ²¡æœ‰å¤ªå¤§çš„overfittingã€‚

ä½†æ˜¯å¯¹äºŽä¸¤ä¸ªæ¨¡åž‹ï¼Œæˆ‘ä»¬å¦‚ä½•åˆ¤æ–­å“ªä¸ªæ¨¡åž‹çš„æ³›åŒ–æ€§èƒ½æ›´ä¼˜å‘¢ï¼Ÿè¿™é‡Œæˆ‘ä»¬æœ‰ä¸»è¦ä»¥ä¸‹ä¸¤ç§æ–¹æ³•ï¼š

å¦‚æžœæ¨¡åž‹Açš„ROCæ›²çº¿å®Œå…¨åŒ…ä½äº†æ¨¡åž‹Bçš„ROCæ›²çº¿ï¼Œé‚£ä¹ˆæˆ‘ä»¬å°±è®¤ä¸ºæ¨¡åž‹Aè¦ä¼˜äºŽæ¨¡åž‹Bï¼›

å¦‚æžœä¸¤æ¡æ›²çº¿æœ‰äº¤å‰çš„è¯ï¼Œæˆ‘ä»¬å°±é€šè¿‡æ¯”è¾ƒROCä¸ŽXï¼ŒYè½´æ‰€å›´å¾—æ›²çº¿çš„é¢ç§¯æ¥åˆ¤æ–­ï¼Œé¢ç§¯è¶Šå¤§ï¼Œæ¨¡åž‹çš„æ€§èƒ½å°±è¶Šä¼˜ï¼Œè¿™ä¸ªé¢ç§¯æˆ‘ä»¬ç§°ä¹‹ä¸ºAUC(area under ROC curve)

4.5 ä»£ç ç¤ºä¾‹
4.5.1 å¯¼å…¥ç›¸å…³å…³å’Œç›¸å…³è®¾ç½®
import pandas as pd
import numpy as np
import warnings
import os
import seaborn as sns
import matplotlib.pyplot as plt
"""
sns ç›¸å…³è®¾ç½®
@return:
"""
# å£°æ˜Žä½¿ç”¨ Seaborn æ ·å¼
sns.set()
# æœ‰äº”ç§seabornçš„ç»˜å›¾é£Žæ ¼ï¼Œå®ƒä»¬åˆ†åˆ«æ˜¯ï¼šdarkgrid, whitegrid, dark, white, ticksã€‚é»˜è®¤çš„ä¸»é¢˜æ˜¯darkgridã€‚
sns.set_style("whitegrid")
# æœ‰å››ä¸ªé¢„ç½®çš„çŽ¯å¢ƒï¼ŒæŒ‰å¤§å°ä»Žå°åˆ°å¤§æŽ’åˆ—åˆ†åˆ«ä¸ºï¼špaper, notebook, talk, posterã€‚å…¶ä¸­ï¼Œnotebookæ˜¯é»˜è®¤çš„ã€‚
sns.set_context('talk')
# ä¸­æ–‡å­—ä½“è®¾ç½®-é»‘ä½“
plt.rcParams['font.sans-serif'] = ['SimHei']
# è§£å†³ä¿å­˜å›¾åƒæ˜¯è´Ÿå·'-'æ˜¾ç¤ºä¸ºæ–¹å—çš„é—®é¢˜
plt.rcParams['axes.unicode_minus'] = False
# è§£å†³Seabornä¸­æ–‡æ˜¾ç¤ºé—®é¢˜å¹¶è°ƒæ•´å­—ä½“å¤§å°
sns.set(font='SimHei')
4.5.2 è¯»å–æ•°æ®
reduce_mem_usage å‡½æ•°é€šè¿‡è°ƒæ•´æ•°æ®ç±»åž‹ï¼Œå¸®åŠ©æˆ‘ä»¬å‡å°‘æ•°æ®åœ¨å†…å­˜ä¸­å ç”¨çš„ç©ºé—´

def reduce_mem_usage(df):
    start_mem = df.memory_usage().sum() 
    print('Memory usage of dataframe is {:.2f} MB'.format(start_mem))
    
    for col in df.columns:
        col_type = df[col].dtype
        
        if col_type != object:
            c_min = df[col].min()
            c_max = df[col].max()
            if str(col_type)[:3] == 'int':
                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:
                    df[col] = df[col].astype(np.int8)
                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:
                    df[col] = df[col].astype(np.int16)
                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:
                    df[col] = df[col].astype(np.int32)
                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:
                    df[col] = df[col].astype(np.int64)  
            else:
                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:
                    df[col] = df[col].astype(np.float16)
                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:
                    df[col] = df[col].astype(np.float32)
                else:
                    df[col] = df[col].astype(np.float64)
        else:
            df[col] = df[col].astype('category')
â€‹
    end_mem = df.memory_usage().sum() 
    print('Memory usage after optimization is: {:.2f} MB'.format(end_mem))
    print('Decreased by {:.1f}%'.format(100 * (start_mem - end_mem) / start_mem))
    
    return df
# è¯»å–æ•°æ®
# æ–‡ä»¶æ˜¯ç‰¹å¾å·¥ç¨‹ä¹‹åŽï¼Œå°†æµ‹è¯•é›†å’Œè®­ç»ƒé›†åˆå¹¶åŽæŠŠæ•°æ®é›†ä¿å­˜ä¸ºdata_for_model.csv
# å…¶ä¸­æ•°æ®é›†ä¸­ç”¨ç‰¹å¾'sample'æ¥åŒºåˆ†æµ‹è¯•é›†å’Œè®­ç»ƒé›†ã€‚åˆ†åˆ«æ˜¯data['sample']='train'ï¼Œdata['sample']='test'ã€‚
# è¿™æ ·åœ¨å»ºæ¨¡çš„æ—¶å€™ç›´æŽ¥è°ƒç”¨å°±è¡Œï¼Œä¸éœ€è¦å†è·‘ä¸€éç‰¹å¾å·¥ç¨‹äº†
â€‹
data = pd.read_csv('dataset/data_for_model.csv')
data = reduce_mem_usage(data)
Memory usage of dataframe is 928000128.00 MB
Memory usage after optimization is: 165006456.00 MB
Decreased by 82.2%
4.5.3 ç®€å•å»ºæ¨¡
Tips1ï¼šé‡‘èžé£ŽæŽ§çš„å®žé™…é¡¹ç›®å¤šæ¶‰åŠåˆ°ä¿¡ç”¨è¯„åˆ†ï¼Œå› æ­¤éœ€è¦æ¨¡åž‹ç‰¹å¾å…·æœ‰è¾ƒå¥½çš„å¯è§£é‡Šæ€§ï¼Œæ‰€ä»¥ç›®å‰åœ¨å®žé™…é¡¹ç›®ä¸­å¤šè¿˜æ˜¯ä»¥é€»è¾‘å›žå½’ä½œä¸ºåŸºç¡€æ¨¡åž‹ã€‚ä½†æ˜¯åœ¨æ¯”èµ›ä¸­ä»¥å¾—åˆ†é«˜ä½Žä¸ºå‡†ï¼Œä¸éœ€è¦ä¸¥è°¨çš„å¯è§£é‡Šæ€§ï¼Œæ‰€ä»¥å¤§å¤šåŸºäºŽé›†æˆç®—æ³•è¿›è¡Œå»ºæ¨¡ã€‚

Tips2ï¼šå› ä¸ºé€»è¾‘å›žå½’çš„ç®—æ³•ç‰¹æ€§ï¼Œéœ€è¦æå‰å¯¹å¼‚å¸¸å€¼ã€ç¼ºå¤±å€¼æ•°æ®è¿›è¡Œå¤„ç†ã€å‚è€ƒtask3éƒ¨åˆ†ã€‘

Tips3ï¼šåŸºäºŽæ ‘æ¨¡åž‹çš„ç®—æ³•ç‰¹æ€§ï¼Œå¼‚å¸¸å€¼ã€ç¼ºå¤±å€¼å¤„ç†å¯ä»¥è·³è¿‡ï¼Œä½†æ˜¯å¯¹äºŽä¸šåŠ¡è¾ƒä¸ºäº†è§£çš„åŒå­¦ä¹Ÿå¯ä»¥è‡ªå·±å¯¹ç¼ºå¤±å¼‚å¸¸å€¼è¿›è¡Œå¤„ç†ï¼Œæ•ˆæžœå¯èƒ½ä¼šæ›´ä¼˜äºŽæ¨¡åž‹å¤„ç†çš„ç»“æžœã€‚

æ³¨ï¼šä»¥ä¸‹å»ºæ¨¡çš„æºæ•°æ®å‚è€ƒbaselineè¿›è¡Œäº†ç›¸åº”çš„ç‰¹å¾å·¥ç¨‹ï¼Œå¯¹äºŽå¼‚å¸¸ç¼ºå¤±å€¼æœªè¿›è¡Œç›¸åº”çš„å¤„ç†æ“ä½œã€‚

å»ºæ¨¡ä¹‹å‰çš„é¢„æ“ä½œ

from sklearn.model_selection import KFold
# åˆ†ç¦»æ•°æ®é›†ï¼Œæ–¹ä¾¿è¿›è¡Œäº¤å‰éªŒè¯
X_train = data.loc[data['sample']=='train', :].drop(['id','issueDate','isDefault', 'sample'], axis=1)
X_test = data.loc[data['sample']=='test', :].drop(['id','issueDate','isDefault', 'sample'], axis=1)
y_train = data.loc[data['sample']=='train', 'isDefault']
â€‹
# 5æŠ˜äº¤å‰éªŒè¯
folds = 5
seed = 2020
kf = KFold(n_splits=folds, shuffle=True, random_state=seed)
ä½¿ç”¨Lightgbmè¿›è¡Œå»ºæ¨¡

"""å¯¹è®­ç»ƒé›†æ•°æ®è¿›è¡Œåˆ’åˆ†ï¼Œåˆ†æˆè®­ç»ƒé›†å’ŒéªŒè¯é›†ï¼Œå¹¶è¿›è¡Œç›¸åº”çš„æ“ä½œ"""
from sklearn.model_selection import train_test_split
import lightgbm as lgb
# æ•°æ®é›†åˆ’åˆ†
X_train_split, X_val, y_train_split, y_val = train_test_split(X_train, y_train, test_size=0.2)
train_matrix = lgb.Dataset(X_train_split, label=y_train_split)
valid_matrix = lgb.Dataset(X_val, label=y_val)
â€‹
params = {
            'boosting_type': 'gbdt',
            'objective': 'binary',
            'learning_rate': 0.1,
            'metric': 'auc',
            'min_child_weight': 1e-3,
            'num_leaves': 31,
            'max_depth': -1,
            'reg_lambda': 0,
            'reg_alpha': 0,
            'feature_fraction': 1,
            'bagging_fraction': 1,
            'bagging_freq': 0,
            'seed': 2020,
            'nthread': 8,
            'silent': True,
            'verbose': -1,
}
â€‹
"""ä½¿ç”¨è®­ç»ƒé›†æ•°æ®è¿›è¡Œæ¨¡åž‹è®­ç»ƒ"""
model = lgb.train(params, train_set=train_matrix, valid_sets=valid_matrix, num_boost_round=20000, verbose_eval=1000, early_stopping_rounds=200)
Training until validation scores don't improve for 200 rounds
Early stopping, best iteration is:
[427]    valid_0's auc: 0.724947
å¯¹éªŒè¯é›†è¿›è¡Œé¢„æµ‹

from sklearn import metrics
from sklearn.metrics import roc_auc_score
â€‹
"""é¢„æµ‹å¹¶è®¡ç®—rocçš„ç›¸å…³æŒ‡æ ‡"""
val_pre_lgb = model.predict(X_val, num_iteration=model.best_iteration)
fpr, tpr, threshold = metrics.roc_curve(y_val, val_pre_lgb)
roc_auc = metrics.auc(fpr, tpr)
print('æœªè°ƒå‚å‰lightgbmå•æ¨¡åž‹åœ¨éªŒè¯é›†ä¸Šçš„AUCï¼š{}'.format(roc_auc))
"""ç”»å‡ºrocæ›²çº¿å›¾"""
plt.figure(figsize=(8, 8))
plt.title('Validation ROC')
plt.plot(fpr, tpr, 'b', label = 'Val AUC = %0.4f' % roc_auc)
plt.ylim(0,1)
plt.xlim(0,1)
plt.legend(loc='best')
plt.title('ROC')
plt.ylabel('True Positive Rate')
plt.xlabel('False Positive Rate')
# ç”»å‡ºå¯¹è§’çº¿
plt.plot([0,1],[0,1],'r--')
plt.show()
æœªè°ƒå‚å‰lightgbmå•æ¨¡åž‹åœ¨éªŒè¯é›†ä¸Šçš„AUCï¼š0.7249469360631181
output_10_1.png

æ›´è¿›ä¸€æ­¥çš„ï¼Œä½¿ç”¨5æŠ˜äº¤å‰éªŒè¯è¿›è¡Œæ¨¡åž‹æ€§èƒ½è¯„ä¼°

import lightgbm as lgb
"""ä½¿ç”¨lightgbm 5æŠ˜äº¤å‰éªŒè¯è¿›è¡Œå»ºæ¨¡é¢„æµ‹"""
cv_scores = []
for i, (train_index, valid_index) in enumerate(kf.split(X_train, y_train)):
    print('************************************ {} ************************************'.format(str(i+1)))
    X_train_split, y_train_split, X_val, y_val = X_train.iloc[train_index], y_train[train_index], X_train.iloc[valid_index], y_train[valid_index]
    
    train_matrix = lgb.Dataset(X_train_split, label=y_train_split)
    valid_matrix = lgb.Dataset(X_val, label=y_val)
â€‹
    params = {
                'boosting_type': 'gbdt',
                'objective': 'binary',
                'learning_rate': 0.1,
                'metric': 'auc',
        
                'min_child_weight': 1e-3,
                'num_leaves': 31,
                'max_depth': -1,
                'reg_lambda': 0,
                'reg_alpha': 0,
                'feature_fraction': 1,
                'bagging_fraction': 1,
                'bagging_freq': 0,
                'seed': 2020,
                'nthread': 8,
                'silent': True,
                'verbose': -1,
    }
    
    model = lgb.train(params, train_set=train_matrix, num_boost_round=20000, valid_sets=valid_matrix, verbose_eval=1000, early_stopping_rounds=200)
    val_pred = model.predict(X_val, num_iteration=model.best_iteration)
    
    cv_scores.append(roc_auc_score(y_val, val_pred))
    print(cv_scores)
â€‹
print("lgb_scotrainre_list:{}".format(cv_scores))
print("lgb_score_mean:{}".format(np.mean(cv_scores)))
print("lgb_score_std:{}".format(np.std(cv_scores)))
...
lgb_scotrainre_list:[0.7303837315833632, 0.7258692125145638, 0.7305149209921737, 0.7296117869375041, 0.7294438695369077]
lgb_score_mean:0.7291647043129024
lgb_score_std:0.0016998349834934656
4.5.4 æ¨¡åž‹è°ƒå‚
1. è´ªå¿ƒè°ƒå‚

å…ˆä½¿ç”¨å½“å‰å¯¹æ¨¡åž‹å½±å“æœ€å¤§çš„å‚æ•°è¿›è¡Œè°ƒä¼˜ï¼Œè¾¾åˆ°å½“å‰å‚æ•°ä¸‹çš„æ¨¡åž‹æœ€ä¼˜åŒ–ï¼Œå†ä½¿ç”¨å¯¹æ¨¡åž‹å½±å“æ¬¡ä¹‹çš„å‚æ•°è¿›è¡Œè°ƒä¼˜ï¼Œå¦‚æ­¤ä¸‹åŽ»ï¼Œç›´åˆ°æ‰€æœ‰çš„å‚æ•°è°ƒæ•´å®Œæ¯•ã€‚

è¿™ä¸ªæ–¹æ³•çš„ç¼ºç‚¹å°±æ˜¯å¯èƒ½ä¼šè°ƒåˆ°å±€éƒ¨æœ€ä¼˜è€Œä¸æ˜¯å…¨å±€æœ€ä¼˜ï¼Œä½†æ˜¯åªéœ€è¦ä¸€æ­¥ä¸€æ­¥çš„è¿›è¡Œå‚æ•°æœ€ä¼˜åŒ–è°ƒè¯•å³å¯ï¼Œå®¹æ˜“ç†è§£ã€‚

éœ€è¦æ³¨æ„çš„æ˜¯åœ¨æ ‘æ¨¡åž‹ä¸­å‚æ•°è°ƒæ•´çš„é¡ºåºï¼Œä¹Ÿå°±æ˜¯å„ä¸ªå‚æ•°å¯¹æ¨¡åž‹çš„å½±å“ç¨‹åº¦ï¼Œè¿™é‡Œåˆ—ä¸¾ä¸€ä¸‹æ—¥å¸¸è°ƒå‚è¿‡ç¨‹ä¸­å¸¸ç”¨çš„å‚æ•°å’Œè°ƒå‚é¡ºåºï¼š

â‘ ï¼šmax_depthã€num_leaves
â‘¡ï¼šmin_data_in_leafã€min_child_weight
â‘¢ï¼šbagging_fractionã€ feature_fractionã€bagging_freq
â‘£ï¼šreg_lambdaã€reg_alpha
â‘¤ï¼šmin_split_gain
from sklearn.model_selection import cross_val_score

# è°ƒobjective
best_obj = dict()
for obj in objective:
    model = LGBMRegressor(objective=obj)
    """é¢„æµ‹å¹¶è®¡ç®—rocçš„ç›¸å…³æŒ‡æ ‡"""
    score = cross_val_score(model, X_train, y_train, cv=5, scoring='roc_auc').mean()
    best_obj[obj] = score

# num_leaves
best_leaves = dict()
for leaves in num_leaves:
    model = LGBMRegressor(objective=min(best_obj.items(), key=lambda x:x[1])[0], num_leaves=leaves)
    """é¢„æµ‹å¹¶è®¡ç®—rocçš„ç›¸å…³æŒ‡æ ‡"""
    score = cross_val_score(model, X_train, y_train, cv=5, scoring='roc_auc').mean()
    best_leaves[leaves] = score

# max_depth
best_depth = dict()
for depth in max_depth:
    model = LGBMRegressor(objective=min(best_obj.items(), key=lambda x:x[1])[0],
                          num_leaves=min(best_leaves.items(), key=lambda x:x[1])[0],
                          max_depth=depth)
    """é¢„æµ‹å¹¶è®¡ç®—rocçš„ç›¸å…³æŒ‡æ ‡"""
    score = cross_val_score(model, X_train, y_train, cv=5, scoring='roc_auc').mean()
    best_depth[depth] = score

"""
å¯ä¾æ¬¡å°†æ¨¡åž‹çš„å‚æ•°é€šè¿‡ä¸Šé¢çš„æ–¹å¼è¿›è¡Œè°ƒæ•´ä¼˜åŒ–ï¼Œå¹¶ä¸”é€šè¿‡å¯è§†åŒ–è§‚å¯Ÿåœ¨æ¯ä¸€ä¸ªæœ€ä¼˜å‚æ•°ä¸‹æ¨¡åž‹çš„å¾—åˆ†æƒ…å†µ
"""
å¯ä¾æ¬¡å°†æ¨¡åž‹çš„å‚æ•°é€šè¿‡ä¸Šé¢çš„æ–¹å¼è¿›è¡Œè°ƒæ•´ä¼˜åŒ–ï¼Œå¹¶ä¸”é€šè¿‡å¯è§†åŒ–è§‚å¯Ÿåœ¨æ¯ä¸€ä¸ªæœ€ä¼˜å‚æ•°ä¸‹æ¨¡åž‹çš„å¾—åˆ†æƒ…å†µ

2. ç½‘æ ¼æœç´¢

sklearn æä¾›GridSearchCVç”¨äºŽè¿›è¡Œç½‘æ ¼æœç´¢ï¼Œåªéœ€è¦æŠŠæ¨¡åž‹çš„å‚æ•°è¾“è¿›åŽ»ï¼Œå°±èƒ½ç»™å‡ºæœ€ä¼˜åŒ–çš„ç»“æžœå’Œå‚æ•°ã€‚ç›¸æ¯”èµ·è´ªå¿ƒè°ƒå‚ï¼Œç½‘æ ¼æœç´¢çš„ç»“æžœä¼šæ›´ä¼˜ï¼Œä½†æ˜¯ç½‘æ ¼æœç´¢åªé€‚åˆäºŽå°æ•°æ®é›†ï¼Œä¸€æ—¦æ•°æ®çš„é‡çº§ä¸ŠåŽ»äº†ï¼Œå¾ˆéš¾å¾—å‡ºç»“æžœã€‚

åŒæ ·ä»¥Lightgbmç®—æ³•ä¸ºä¾‹ï¼Œè¿›è¡Œç½‘æ ¼æœç´¢è°ƒå‚ï¼š

"""é€šè¿‡ç½‘æ ¼æœç´¢ç¡®å®šæœ€ä¼˜å‚æ•°"""
from sklearn.model_selection import GridSearchCV

def get_best_cv_params(learning_rate=0.1, n_estimators=581, num_leaves=31, max_depth=-1, bagging_fraction=1.0, 
                       feature_fraction=1.0, bagging_freq=0, min_data_in_leaf=20, min_child_weight=0.001, 
                       min_split_gain=0, reg_lambda=0, reg_alpha=0, param_grid=None):
    # è®¾ç½®5æŠ˜äº¤å‰éªŒè¯
    cv_fold = StratifiedKFold(n_splits=5, random_state=0, shuffle=True, )

    model_lgb = lgb.LGBMClassifier(learning_rate=learning_rate,
                                   n_estimators=n_estimators,
                                   num_leaves=num_leaves,
                                   max_depth=max_depth,
                                   bagging_fraction=bagging_fraction,
                                   feature_fraction=feature_fraction,
                                   bagging_freq=bagging_freq,
                                   min_data_in_leaf=min_data_in_leaf,
                                   min_child_weight=min_child_weight,
                                   min_split_gain=min_split_gain,
                                   reg_lambda=reg_lambda,
                                   reg_alpha=reg_alpha,
                                   n_jobs= 8
                                  )
    grid_search = GridSearchCV(estimator=model_lgb, 
                               cv=cv_fold,
                               param_grid=param_grid,
                               scoring='roc_auc'
                              )
    grid_search.fit(X_train, y_train)

    print('æ¨¡åž‹å½“å‰æœ€ä¼˜å‚æ•°ä¸º:{}'.format(grid_search.best_params_))
    print('æ¨¡åž‹å½“å‰æœ€ä¼˜å¾—åˆ†ä¸º:{}'.format(grid_search.best_score_))
"""ä»¥ä¸‹ä»£ç æœªè¿è¡Œï¼Œè€—æ—¶è¾ƒé•¿ï¼Œè¯·è°¨æ…Žè¿è¡Œï¼Œä¸”æ¯ä¸€æ­¥çš„æœ€ä¼˜å‚æ•°éœ€è¦åœ¨ä¸‹ä¸€æ­¥è¿›è¡Œæ‰‹åŠ¨æ›´æ–°ï¼Œè¯·æ³¨æ„"""

"""
éœ€è¦æ³¨æ„ä¸€ä¸‹çš„æ˜¯ï¼Œé™¤äº†èŽ·å–ä¸Šé¢çš„èŽ·å–num_boost_roundæ—¶å€™ç”¨çš„æ˜¯åŽŸç”Ÿçš„lightgbmï¼ˆå› ä¸ºè¦ç”¨è‡ªå¸¦çš„cvï¼‰
ä¸‹é¢é…åˆGridSearchCVæ—¶å¿…é¡»ä½¿ç”¨sklearnæŽ¥å£çš„lightgbmã€‚
"""
"""è®¾ç½®n_estimators ä¸º581ï¼Œè°ƒæ•´num_leaveså’Œmax_depthï¼Œè¿™é‡Œé€‰æ‹©å…ˆç²—è°ƒå†ç»†è°ƒ"""
lgb_params = {'num_leaves': range(10, 80, 5), 'max_depth': range(3,10,2)}
get_best_cv_params(learning_rate=0.1, n_estimators=581, num_leaves=None, max_depth=None, min_data_in_leaf=20, 
                   min_child_weight=0.001,bagging_fraction=1.0, feature_fraction=1.0, bagging_freq=0, 
                   min_split_gain=0, reg_lambda=0, reg_alpha=0, param_grid=lgb_params)

"""num_leavesä¸º30ï¼Œmax_depthä¸º7ï¼Œè¿›ä¸€æ­¥ç»†è°ƒnum_leaveså’Œmax_depth"""
lgb_params = {'num_leaves': range(25, 35, 1), 'max_depth': range(5,9,1)}
get_best_cv_params(learning_rate=0.1, n_estimators=85, num_leaves=None, max_depth=None, min_data_in_leaf=20, 
                   min_child_weight=0.001,bagging_fraction=1.0, feature_fraction=1.0, bagging_freq=0, 
                   min_split_gain=0, reg_lambda=0, reg_alpha=0, param_grid=lgb_params)

"""
ç¡®å®šmin_data_in_leafä¸º45ï¼Œmin_child_weightä¸º0.001 ï¼Œä¸‹é¢è¿›è¡Œbagging_fractionã€feature_fractionå’Œbagging_freqçš„è°ƒå‚
"""
lgb_params = {'bagging_fraction': [i/10 for i in range(5,10,1)], 
              'feature_fraction': [i/10 for i in range(5,10,1)],
              'bagging_freq': range(0,81,10)
             }
get_best_cv_params(learning_rate=0.1, n_estimators=85, num_leaves=29, max_depth=7, min_data_in_leaf=45, 
                   min_child_weight=0.001,bagging_fraction=None, feature_fraction=None, bagging_freq=None, 
                   min_split_gain=0, reg_lambda=0, reg_alpha=0, param_grid=lgb_params)

"""
ç¡®å®šbagging_fractionä¸º0.4ã€feature_fractionä¸º0.6ã€bagging_freqä¸º ï¼Œä¸‹é¢è¿›è¡Œreg_lambdaã€reg_alphaçš„è°ƒå‚
"""
lgb_params = {'reg_lambda': [0,0.001,0.01,0.03,0.08,0.3,0.5], 'reg_alpha': [0,0.001,0.01,0.03,0.08,0.3,0.5]}
get_best_cv_params(learning_rate=0.1, n_estimators=85, num_leaves=29, max_depth=7, min_data_in_leaf=45, 
                   min_child_weight=0.001,bagging_fraction=0.9, feature_fraction=0.9, bagging_freq=40, 
                   min_split_gain=0, reg_lambda=None, reg_alpha=None, param_grid=lgb_params)

"""
ç¡®å®šreg_lambdaã€reg_alphaéƒ½ä¸º0ï¼Œä¸‹é¢è¿›è¡Œmin_split_gainçš„è°ƒå‚
"""
lgb_params = {'min_split_gain': [i/10 for i in range(0,11,1)]}
get_best_cv_params(learning_rate=0.1, n_estimators=85, num_leaves=29, max_depth=7, min_data_in_leaf=45, 
                   min_child_weight=0.001,bagging_fraction=0.9, feature_fraction=0.9, bagging_freq=40, 
                   min_split_gain=None, reg_lambda=0, reg_alpha=0, param_grid=lgb_params)
"""
å‚æ•°ç¡®å®šå¥½äº†ä»¥åŽï¼Œæˆ‘ä»¬è®¾ç½®ä¸€ä¸ªæ¯”è¾ƒå°çš„learning_rate 0.005ï¼Œæ¥ç¡®å®šæœ€ç»ˆçš„num_boost_round
"""
# è®¾ç½®5æŠ˜äº¤å‰éªŒè¯
# cv_fold = StratifiedKFold(n_splits=5, random_state=0, shuffle=True, )
final_params = {
                'boosting_type': 'gbdt',
                'learning_rate': 0.01,
                'num_leaves': 29,
                'max_depth': 7,
                'min_data_in_leaf':45,
                'min_child_weight':0.001,
                'bagging_fraction': 0.9,
                'feature_fraction': 0.9,
                'bagging_freq': 40,
                'min_split_gain': 0,
                'reg_lambda':0,
                'reg_alpha':0,
                'nthread': 6
               }

cv_result = lgb.cv(train_set=lgb_train,
                   early_stopping_rounds=20,
                   num_boost_round=5000,
                   nfold=5,
                   stratified=True,
                   shuffle=True,
                   params=final_params,
                   metrics='auc',
                   seed=0,
                  )

print('è¿­ä»£æ¬¡æ•°{}'.format(len(cv_result['auc-mean'])))
print('äº¤å‰éªŒè¯çš„AUCä¸º{}'.format(max(cv_result['auc-mean'])))
åœ¨å®žé™…è°ƒæ•´è¿‡ç¨‹ä¸­ï¼Œå¯å…ˆè®¾ç½®ä¸€ä¸ªè¾ƒå¤§çš„å­¦ä¹ çŽ‡ï¼ˆä¸Šé¢çš„ä¾‹å­ä¸­0.1ï¼‰ï¼Œé€šè¿‡LgbåŽŸç”Ÿçš„cvå‡½æ•°è¿›è¡Œæ ‘ä¸ªæ•°çš„ç¡®å®šï¼Œä¹‹åŽå†é€šè¿‡ä¸Šé¢çš„å®žä¾‹ä»£ç è¿›è¡Œå‚æ•°çš„è°ƒæ•´ä¼˜åŒ–ã€‚

æœ€åŽé’ˆå¯¹æœ€ä¼˜çš„å‚æ•°è®¾ç½®ä¸€ä¸ªè¾ƒå°çš„å­¦ä¹ çŽ‡ï¼ˆä¾‹å¦‚0.05ï¼‰ï¼ŒåŒæ ·é€šè¿‡cvå‡½æ•°ç¡®å®šæ ‘çš„ä¸ªæ•°ï¼Œç¡®å®šæœ€ç»ˆçš„å‚æ•°ã€‚

éœ€è¦æ³¨æ„çš„æ˜¯ï¼Œé’ˆå¯¹å¤§æ•°æ®é›†ï¼Œä¸Šé¢æ¯ä¸€å±‚å‚æ•°çš„è°ƒæ•´éƒ½éœ€è¦è€—è´¹è¾ƒé•¿æ—¶é—´ï¼Œ

è´å¶æ–¯è°ƒå‚

åœ¨ä½¿ç”¨ä¹‹å‰éœ€è¦å…ˆå®‰è£…åŒ…bayesian-optimizationï¼Œè¿è¡Œå¦‚ä¸‹å‘½ä»¤å³å¯ï¼š

pip install bayesian-optimization
è´å¶æ–¯è°ƒå‚çš„ä¸»è¦æ€æƒ³æ˜¯ï¼šç»™å®šä¼˜åŒ–çš„ç›®æ ‡å‡½æ•°(å¹¿ä¹‰çš„å‡½æ•°ï¼Œåªéœ€æŒ‡å®šè¾“å…¥å’Œè¾“å‡ºå³å¯ï¼Œæ— éœ€çŸ¥é“å†…éƒ¨ç»“æž„ä»¥åŠæ•°å­¦æ€§è´¨)ï¼Œé€šè¿‡ä¸æ–­åœ°æ·»åŠ æ ·æœ¬ç‚¹æ¥æ›´æ–°ç›®æ ‡å‡½æ•°çš„åŽéªŒåˆ†å¸ƒ(é«˜æ–¯è¿‡ç¨‹,ç›´åˆ°åŽéªŒåˆ†å¸ƒåŸºæœ¬è´´åˆäºŽçœŸå®žåˆ†å¸ƒï¼‰ã€‚ç®€å•çš„è¯´ï¼Œå°±æ˜¯è€ƒè™‘äº†ä¸Šä¸€æ¬¡å‚æ•°çš„ä¿¡æ¯ï¼Œä»Žè€Œæ›´å¥½çš„è°ƒæ•´å½“å‰çš„å‚æ•°ã€‚

è´å¶æ–¯è°ƒå‚çš„æ­¥éª¤å¦‚ä¸‹ï¼š

å®šä¹‰ä¼˜åŒ–å‡½æ•°(rf_cvï¼‰
å»ºç«‹æ¨¡åž‹
å®šä¹‰å¾…ä¼˜åŒ–çš„å‚æ•°
å¾—åˆ°ä¼˜åŒ–ç»“æžœï¼Œå¹¶è¿”å›žè¦ä¼˜åŒ–çš„åˆ†æ•°æŒ‡æ ‡
from sklearn.model_selection import cross_val_score

"""å®šä¹‰ä¼˜åŒ–å‡½æ•°"""
def rf_cv_lgb(num_leaves, max_depth, bagging_fraction, feature_fraction, bagging_freq, min_data_in_leaf, 
              min_child_weight, min_split_gain, reg_lambda, reg_alpha):
    # å»ºç«‹æ¨¡åž‹
    model_lgb = lgb.LGBMClassifier(boosting_type='gbdt', bjective='binary', metric='auc',
                                   learning_rate=0.1, n_estimators=5000,
                                   num_leaves=int(num_leaves), max_depth=int(max_depth), 
                                   bagging_fraction=round(bagging_fraction, 2), feature_fraction=round(feature_fraction, 2),
                                   bagging_freq=int(bagging_freq), min_data_in_leaf=int(min_data_in_leaf),
                                   min_child_weight=min_child_weight, min_split_gain=min_split_gain,
                                   reg_lambda=reg_lambda, reg_alpha=reg_alpha,
                                   n_jobs= 8
                                  )

    val = cross_val_score(model_lgb, X_train_split, y_train_split, cv=5, scoring='roc_auc').mean()

    return val
from bayes_opt import BayesianOptimization
"""å®šä¹‰ä¼˜åŒ–å‚æ•°"""
bayes_lgb = BayesianOptimization(
    rf_cv_lgb, 
    {
        'num_leaves':(10, 200),
        'max_depth':(3, 20),
        'bagging_fraction':(0.5, 1.0),
        'feature_fraction':(0.5, 1.0),
        'bagging_freq':(0, 100),
        'min_data_in_leaf':(10,100),
        'min_child_weight':(0, 10),
        'min_split_gain':(0.0, 1.0),
        'reg_alpha':(0.0, 10),
        'reg_lambda':(0.0, 10),
    }
)

"""å¼€å§‹ä¼˜åŒ–"""
bayes_lgb.maximize(n_iter=10)
|   iter    |  target   | baggin... | baggin... | featur... | max_depth | min_ch... | min_da... | min_sp... | num_le... | reg_alpha | reg_la... |
-------------------------------------------------------------------------------------------------------------------------------------------------
| [0m 1       [0m | [0m 0.7263  [0m | [0m 0.7196  [0m | [0m 80.73   [0m | [0m 0.7988  [0m | [0m 19.17   [0m | [0m 5.751   [0m | [0m 40.71   [0m | [0m 0.9548  [0m | [0m 176.2   [0m | [0m 2.939   [0m | [0m 7.212   [0m |
| [95m 2       [0m | [95m 0.7279  [0m | [95m 0.8997  [0m | [95m 74.72   [0m | [95m 0.5904  [0m | [95m 7.259   [0m | [95m 6.175   [0m | [95m 92.03   [0m | [95m 0.4027  [0m | [95m 51.65   [0m | [95m 6.404   [0m | [95m 4.781   [0m |
| [0m 3       [0m | [0m 0.7207  [0m | [0m 0.5133  [0m | [0m 16.53   [0m | [0m 0.9536  [0m | [0m 4.974   [0m | [0m 2.37    [0m | [0m 98.08   [0m | [0m 0.7909  [0m | [0m 52.12   [0m | [0m 4.443   [0m | [0m 4.429   [0m |
| [0m 4       [0m | [0m 0.7276  [0m | [0m 0.6265  [0m | [0m 53.12   [0m | [0m 0.7307  [0m | [0m 10.67   [0m | [0m 1.824   [0m | [0m 18.98   [0m | [0m 0.954   [0m | [0m 60.47   [0m | [0m 6.963   [0m | [0m 1.999   [0m |
| [0m 5       [0m | [0m 0.6963  [0m | [0m 0.6509  [0m | [0m 11.58   [0m | [0m 0.5386  [0m | [0m 11.21   [0m | [0m 7.85    [0m | [0m 11.4    [0m | [0m 0.4269  [0m | [0m 153.0   [0m | [0m 0.5227  [0m | [0m 2.257   [0m |
| [0m 6       [0m | [0m 0.7276  [0m | [0m 0.6241  [0m | [0m 49.76   [0m | [0m 0.6057  [0m | [0m 10.34   [0m | [0m 1.718   [0m | [0m 22.43   [0m | [0m 0.8294  [0m | [0m 55.68   [0m | [0m 6.759   [0m | [0m 2.6     [0m |
| [95m 7       [0m | [95m 0.7283  [0m | [95m 0.9815  [0m | [95m 96.15   [0m | [95m 0.6961  [0m | [95m 19.45   [0m | [95m 1.627   [0m | [95m 37.7    [0m | [95m 0.4185  [0m | [95m 14.22   [0m | [95m 7.057   [0m | [95m 9.924   [0m |
| [0m 8       [0m | [0m 0.7278  [0m | [0m 0.7139  [0m | [0m 96.83   [0m | [0m 0.5063  [0m | [0m 3.941   [0m | [0m 1.469   [0m | [0m 97.28   [0m | [0m 0.07553 [0m | [0m 196.9   [0m | [0m 7.988   [0m | [0m 2.159   [0m |
| [0m 9       [0m | [0m 0.7195  [0m | [0m 0.5352  [0m | [0m 98.72   [0m | [0m 0.9699  [0m | [0m 4.445   [0m | [0m 1.767   [0m | [0m 13.91   [0m | [0m 0.1647  [0m | [0m 191.5   [0m | [0m 4.003   [0m | [0m 2.027   [0m |
| [0m 10      [0m | [0m 0.7281  [0m | [0m 0.7281  [0m | [0m 73.63   [0m | [0m 0.5598  [0m | [0m 19.29   [0m | [0m 0.5344  [0m | [0m 99.66   [0m | [0m 0.933   [0m | [0m 101.4   [0m | [0m 8.836   [0m | [0m 0.9222  [0m |
| [0m 11      [0m | [0m 0.7279  [0m | [0m 0.8213  [0m | [0m 0.05856 [0m | [0m 0.7626  [0m | [0m 17.49   [0m | [0m 8.447   [0m | [0m 10.71   [0m | [0m 0.3252  [0m | [0m 13.64   [0m | [0m 9.319   [0m | [0m 0.4747  [0m |
| [0m 12      [0m | [0m 0.7281  [0m | [0m 0.8372  [0m | [0m 95.71   [0m | [0m 0.9598  [0m | [0m 10.32   [0m | [0m 8.394   [0m | [0m 15.23   [0m | [0m 0.4909  [0m | [0m 94.48   [0m | [0m 9.486   [0m | [0m 9.044   [0m |
| [0m 13      [0m | [0m 0.6993  [0m | [0m 0.5183  [0m | [0m 99.02   [0m | [0m 0.542   [0m | [0m 15.5    [0m | [0m 8.35    [0m | [0m 38.15   [0m | [0m 0.4079  [0m | [0m 58.01   [0m | [0m 0.2668  [0m | [0m 1.652   [0m |
| [0m 14      [0m | [0m 0.7267  [0m | [0m 0.7933  [0m | [0m 4.459   [0m | [0m 0.79    [0m | [0m 7.557   [0m | [0m 2.43    [0m | [0m 27.91   [0m | [0m 0.8725  [0m | [0m 28.32   [0m | [0m 9.967   [0m | [0m 9.885   [0m |
| [0m 15      [0m | [0m 0.6979  [0m | [0m 0.9419  [0m | [0m 1.22    [0m | [0m 0.835   [0m | [0m 11.56   [0m | [0m 9.962   [0m | [0m 93.79   [0m | [0m 0.018   [0m | [0m 197.6   [0m | [0m 9.711   [0m | [0m 3.78    [0m |
=================================================================================================================================================
"""æ˜¾ç¤ºä¼˜åŒ–ç»“æžœ"""
bayes_lgb.max
{'target': 0.7282530196283977,
 'params': {'bagging_fraction': 0.9815471914843896,
  'bagging_freq': 96.14757648686668,
  'feature_fraction': 0.6961281791730929,
  'max_depth': 19.45450235568963,
  'min_child_weight': 1.6266132496156782,
  'min_data_in_leaf': 37.697878831472295,
  'min_split_gain': 0.4184947943942168,
  'num_leaves': 14.221122487200399,
  'reg_alpha': 7.056502173310882,
  'reg_lambda': 9.924023764203156}}
å‚æ•°ä¼˜åŒ–å®ŒæˆåŽï¼Œæˆ‘ä»¬å¯ä»¥æ ¹æ®ä¼˜åŒ–åŽçš„å‚æ•°å»ºç«‹æ–°çš„æ¨¡åž‹ï¼Œé™ä½Žå­¦ä¹ çŽ‡å¹¶å¯»æ‰¾æœ€ä¼˜æ¨¡åž‹è¿­ä»£æ¬¡æ•°

"""è°ƒæ•´ä¸€ä¸ªè¾ƒå°çš„å­¦ä¹ çŽ‡ï¼Œå¹¶é€šè¿‡cvå‡½æ•°ç¡®å®šå½“å‰æœ€ä¼˜çš„è¿­ä»£æ¬¡æ•°"""
base_params_lgb = {
                    'boosting_type': 'gbdt',
                    'objective': 'binary',
                    'metric': 'auc',
                    'learning_rate': 0.01,
                    'num_leaves': 14,
                    'max_depth': 19,
                    'min_data_in_leaf': 37,
                    'min_child_weight':1.6,
                    'bagging_fraction': 0.98,
                    'feature_fraction': 0.69,
                    'bagging_freq': 96,
                    'reg_lambda': 9,
                    'reg_alpha': 7,
                    'min_split_gain': 0.4,
                    'nthread': 8,
                    'seed': 2020,
                    'silent': True,
                    'verbose': -1,
}

cv_result_lgb = lgb.cv(
    train_set=train_matrix,
    early_stopping_rounds=1000, 
    num_boost_round=20000,
    nfold=5,
    stratified=True,
    shuffle=True,
    params=base_params_lgb,
    metrics='auc',
    seed=0
)

print('è¿­ä»£æ¬¡æ•°{}'.format(len(cv_result_lgb['auc-mean'])))
print('æœ€ç»ˆæ¨¡åž‹çš„AUCä¸º{}'.format(max(cv_result_lgb['auc-mean'])))
è¿­ä»£æ¬¡æ•°14269
æœ€ç»ˆæ¨¡åž‹çš„AUCä¸º0.7315032037635779
æ¨¡åž‹å‚æ•°å·²ç»ç¡®å®šï¼Œå»ºç«‹æœ€ç»ˆæ¨¡åž‹å¹¶å¯¹éªŒè¯é›†è¿›è¡ŒéªŒè¯

import lightgbm as lgb
"""ä½¿ç”¨lightgbm 5æŠ˜äº¤å‰éªŒè¯è¿›è¡Œå»ºæ¨¡é¢„æµ‹"""
cv_scores = []
for i, (train_index, valid_index) in enumerate(kf.split(X_train, y_train)):
    print('************************************ {} ************************************'.format(str(i+1)))
    X_train_split, y_train_split, X_val, y_val = X_train.iloc[train_index], y_train[train_index], X_train.iloc[valid_index], y_train[valid_index]

    train_matrix = lgb.Dataset(X_train_split, label=y_train_split)
    valid_matrix = lgb.Dataset(X_val, label=y_val)

    params = {
                'boosting_type': 'gbdt',
                'objective': 'binary',
                'metric': 'auc',
                'learning_rate': 0.01,
                'num_leaves': 14,
                'max_depth': 19,
                'min_data_in_leaf': 37,
                'min_child_weight':1.6,
                'bagging_fraction': 0.98,
                'feature_fraction': 0.69,
                'bagging_freq': 96,
                'reg_lambda': 9,
                'reg_alpha': 7,
                'min_split_gain': 0.4,
                'nthread': 8,
                'seed': 2020,
                'silent': True,
    }

    model = lgb.train(params, train_set=train_matrix, num_boost_round=14269, valid_sets=valid_matrix, verbose_eval=1000, early_stopping_rounds=200)
    val_pred = model.predict(X_val, num_iteration=model.best_iteration)

    cv_scores.append(roc_auc_score(y_val, val_pred))
    print(cv_scores)

print("lgb_scotrainre_list:{}".format(cv_scores))
print("lgb_score_mean:{}".format(np.mean(cv_scores)))
print("lgb_score_std:{}".format(np.std(cv_scores)))
...
lgb_scotrainre_list:[0.7329726464187137, 0.7294292852806246, 0.7341505801564857, 0.7328331383185244, 0.7317405262608612]
lgb_score_mean:0.732225235287042
lgb_score_std:0.0015929470575114753
é€šè¿‡5æŠ˜äº¤å‰éªŒè¯å¯ä»¥å‘çŽ°ï¼Œæ¨¡åž‹è¿­ä»£æ¬¡æ•°åœ¨13000æ¬¡çš„æ—¶å€™ä¼šåœä¹‹ï¼Œé‚£ä¹ˆæˆ‘ä»¬åœ¨å»ºç«‹æ–°æ¨¡åž‹æ—¶ç›´æŽ¥è®¾ç½®æœ€å¤§è¿­ä»£æ¬¡æ•°ï¼Œå¹¶ä½¿ç”¨éªŒè¯é›†è¿›è¡Œæ¨¡åž‹é¢„æµ‹

""""""
base_params_lgb = {
                    'boosting_type': 'gbdt',
                    'objective': 'binary',
                    'metric': 'auc',
                    'learning_rate': 0.01,
                    'num_leaves': 14,
                    'max_depth': 19,
                    'min_data_in_leaf': 37,
                    'min_child_weight':1.6,
                    'bagging_fraction': 0.98,
                    'feature_fraction': 0.69,
                    'bagging_freq': 96,
                    'reg_lambda': 9,
                    'reg_alpha': 7,
                    'min_split_gain': 0.4,
                    'nthread': 8,
                    'seed': 2020,
                    'silent': True,
}

"""ä½¿ç”¨è®­ç»ƒé›†æ•°æ®è¿›è¡Œæ¨¡åž‹è®­ç»ƒ"""
final_model_lgb = lgb.train(base_params_lgb, train_set=train_matrix, valid_sets=valid_matrix, num_boost_round=13000, verbose_eval=1000, early_stopping_rounds=200)

"""é¢„æµ‹å¹¶è®¡ç®—rocçš„ç›¸å…³æŒ‡æ ‡"""
val_pre_lgb = final_model_lgb.predict(X_val)
fpr, tpr, threshold = metrics.roc_curve(y_val, val_pre_lgb)
roc_auc = metrics.auc(fpr, tpr)
print('è°ƒå‚åŽlightgbmå•æ¨¡åž‹åœ¨éªŒè¯é›†ä¸Šçš„AUCï¼š{}'.format(roc_auc))
"""ç”»å‡ºrocæ›²çº¿å›¾"""
plt.figure(figsize=(8, 8))
plt.title('Validation ROC')
plt.plot(fpr, tpr, 'b', label = 'Val AUC = %0.4f' % roc_auc)
plt.ylim(0,1)
plt.xlim(0,1)
plt.legend(loc='best')
plt.title('ROC')
plt.ylabel('True Positive Rate')
plt.xlabel('False Positive Rate')
# ç”»å‡ºå¯¹è§’çº¿
plt.plot([0,1],[0,1],'r--')
plt.show()
Training until validation scores don't improve for 200 rounds
[1000]    valid_0's auc: 0.723676
[2000]    valid_0's auc: 0.727282
[3000]    valid_0's auc: 0.728593
[4000]    valid_0's auc: 0.729493
[5000]    valid_0's auc: 0.730087
[6000]    valid_0's auc: 0.730515
[7000]    valid_0's auc: 0.730872
[8000]    valid_0's auc: 0.731121
[9000]    valid_0's auc: 0.731351
[10000]    valid_0's auc: 0.731502
[11000]    valid_0's auc: 0.731707
Early stopping, best iteration is:
[11192]    valid_0's auc: 0.731741
è°ƒå‚åŽlightgbmå•æ¨¡åž‹åœ¨éªŒè¯é›†ä¸Šçš„AUCï¼š0.7317405262608612
output_29_1.png

å¯ä»¥çœ‹åˆ°ç›¸æ¯”æœ€æ—©çš„åŽŸå§‹å‚æ•°ï¼Œæ¨¡åž‹çš„æ€§èƒ½è¿˜æ˜¯æœ‰æå‡çš„

  """ä¿å­˜æ¨¡åž‹åˆ°æœ¬åœ°"""
  # ä¿å­˜æ¨¡åž‹
  import pickle
  pickle.dump(final_model_lgb, open('dataset/model_lgb_best.pkl', 'wb'))
æ¨¡åž‹è°ƒå‚å°æ€»ç»“

é›†æˆæ¨¡åž‹å†…ç½®çš„cvå‡½æ•°å¯ä»¥è¾ƒå¿«çš„è¿›è¡Œå•ä¸€å‚æ•°çš„è°ƒèŠ‚ï¼Œä¸€èˆ¬å¯ä»¥ç”¨æ¥ä¼˜å…ˆç¡®å®šæ ‘æ¨¡åž‹çš„è¿­ä»£æ¬¡æ•°

æ•°æ®é‡è¾ƒå¤§çš„æ—¶å€™ï¼ˆä¾‹å¦‚æœ¬æ¬¡é¡¹ç›®çš„æ•°æ®ï¼‰ï¼Œç½‘æ ¼æœç´¢è°ƒå‚ä¼šç‰¹åˆ«ç‰¹åˆ«æ…¢ï¼Œä¸å»ºè®®å°è¯•

é›†æˆæ¨¡åž‹ä¸­åŽŸç”Ÿåº“å’Œsklearnä¸‹çš„åº“éƒ¨åˆ†å‚æ•°ä¸ä¸€è‡´ï¼Œéœ€è¦æ³¨æ„ï¼Œå…·ä½“å¯ä»¥å‚è€ƒxgbå’Œlgbçš„å®˜æ–¹API

xgbåŽŸç”Ÿåº“APIï¼Œsklearnåº“ä¸‹xgbAPI

lgbåŽŸç”Ÿåº“APIï¼Œ sklearnåº“ä¸‹lgbAPI

4.6 ç»éªŒæ€»ç»“
åœ¨æœ¬èŠ‚ä¸­ï¼Œæˆ‘ä»¬ä¸»è¦å®Œæˆäº†å»ºæ¨¡ä¸Žè°ƒå‚çš„å·¥ä½œï¼Œé¦–å…ˆåœ¨å»ºæ¨¡çš„è¿‡ç¨‹ä¸­é€šè¿‡åˆ’åˆ†æ•°æ®é›†ã€äº¤å‰éªŒè¯ç­‰æ–¹å¼å¯¹æ¨¡åž‹çš„æ€§èƒ½è¿›è¡Œè¯„ä¼°éªŒè¯ï¼Œå¹¶é€šè¿‡å¯è§†åŒ–æ–¹å¼ç»˜åˆ¶æ¨¡åž‹ROCæ›²çº¿ã€‚

æœ€åŽæˆ‘ä»¬å¯¹æ¨¡åž‹è¿›è¡Œè°ƒå‚ï¼Œè¿™éƒ¨åˆ†ä»‹ç»äº†è´ªå¿ƒè°ƒå‚ã€ç½‘æ ¼æœç´¢è°ƒå‚ã€è´å¶æ–¯è°ƒå‚å…±ä¸‰ç§è°ƒå‚æ‰‹æ®µï¼Œé‡ç‚¹ä½¿ç”¨è´å¶æ–¯è°ƒå‚å¯¹æœ¬æ¬¡é¡¹ç›®è¿›è¡Œç®€å•ä¼˜åŒ–ï¼Œå¤§å®¶åœ¨å®žé™…æ“ä½œçš„è¿‡ç¨‹ä¸­å¯ä»¥å‚è€ƒè°ƒå‚æ€è·¯è¿›è¡Œä¼˜åŒ–ï¼Œä¸å¿…æ‹˜æ³¥äºŽä»¥ä¸Šæ•™ç¨‹æ‰€å†™çš„å…·ä½“å®žä¾‹ã€‚
