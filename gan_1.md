目录
生成式模型与判别式模型
1. 判别式模型
2. 生成式模型
3. 常见模型
4. 判别式模型与生成式模型比较

GAN的基本原理
1. 基本原理
2. 优化目标与求解
3. 如何训练
4. GAN的主要问题

GAN的应用
1. 数据生成
2. 风格迁移
3. 超分辨重建

参考文献

生成对抗网络（GANs）是当今计算机科学领域最有趣的想法之一。两个模型通过对抗过程同时训练。一个生成器（“艺术家”）学习创造看起来真实的图像，而判别器（“艺术评论家”）学习区分真假图像。

训练过程中，生成器在生成逼真图像方面逐渐变强，而判别器在辨别这些图像的能力上逐渐变强。当判别器不再能够区分真实图片和伪造图片时，训练过程达到平衡。

生成式模型与判别式模型
正式说 GAN 之前我们先说一下判别式模型和生成式模型。

1. 判别式模型
判别式模型，即 Discriminative Model，又被称为条件概率模型，它估计的是条件概率分布(conditional distribution)， p(class|context) 。

举个例子，我们给定(x,y)对，4个样本。(1,0), (1,0), (2,0), (2, 1)，p(y|x)是事件x发生时y的条件概率，它的计算如下：

判别式模型.

2. 生成式模型
即 Generative Model ，生成式模型 ，它估计的是联合概率分布（joint probability distribution），p(class,context)=p(class|context)*p(context) 。p(x,y)，即事件x与事件y同时发生的概率。同样以上面的样本为例，它的计算如下：

生成式模型

3. 常见模型
常见的判别式模型有 Logistic Regression，Linear Regression，SVM，Traditional Neural Networks Nearest Neighbor，CRF 等。

常见的生成式模型有 Naive Bayes，Mixtures of Gaussians， HMMs，Markov Random Fields 等。

得分点：（CV 面试中会出现）

4. 判别式模型与生成式模型比较
判别式模型 ，优点是分类边界灵活 ，学习简单，性能较好 ；缺点是不能得到概率分布 。

生成式模型 ，优点是收敛速度快，可学习分布，可应对隐变量 ；缺点是学习复杂 ，分类性能较差。

判别式模型与生成式模型比较

上面是一个分类例子，可知判别式模型，有清晰的分界面，而生成式模型，有清晰的概率密度分布。生成式模型，可以转换为判别式模型，反之则不能。

GAN的基本原理
GAN，即Generative adversarial net，它同时包含判别式模型和生成式模型，一个经典的网络结构如下：

GAN原理-1

1. 基本原理
GAN原理-2

GAN的原理很简单，它包括两个网络，一个生成网络，不断生成数据分布。一个判别网络，判断生成的数据是否为真实数据。上图是原理展示，黑色虚线是真实分布，绿色实线是生成模型的学习过程，蓝色虚线是判别模型的学习过程，两者相互对抗，共同学习到最优状态。

2. 优化目标与求解
下面是它的优化目标。

优化目标与求解-1

D是判别器，它的学习目标，是最大化上面的式子，而G是生成器，它的学习目标，是最小化上面的式子。上面问题的求解，通过迭代求解D和G来完成。

要求解上面的式子，等价于求解下面的式子。

优化目标与求解-2

其中D(x)属于(0,1)，上式是alog(y) + blog(1−y)的形式，取得最大值的条件是D(x)=a/(a+b)，此时等价于下面式子。

优化目标与求解-3

如果用KL散度来描述，上面的式子等于下面的式子。优化目标与求解-4

当且仅当pdata(x)=pg(x)时，取得极小值-log4，此时d=0.5，无法分辨真实样本和假样本。

GAN从理论上，被证实存在全局最优解。

3. 如何训练
如何训练

直接从原始论文中截取伪代码了，可见，就是采用判别式模型和生成式模型分别循环依次迭代的方法，与CNN一样，使用梯度下降来优化。

4. GAN的主要问题
GAN从本质上来说，有与CNN不同的特点，因为GAN的训练是依次迭代D和G，如果判别器D学的不好，生成器G得不到正确反馈，就无法稳定学习。如果判别器D学的太好，整个loss迅速下降，G就无法继续学习。

GAN的优化需要生成器和判别器达到纳什均衡，但是因为判别器D和生成器G是分别训练的，纳什平衡并不一定能达到，这是早期GAN难以训练的主要原因。另外，最初的损失函数也不是最优的，这些就留待我们的下篇再细讲吧，下面欣赏一下GAN的一些精彩的应用。
